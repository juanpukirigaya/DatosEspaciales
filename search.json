[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introducción al análisis de datos espaciales",
    "section": "",
    "text": "Presentación\nAquí se encontrarán herramientas para un análisis básico de datos espaciales.\nComo en muchas otras áreas de la estadística, se busca hacer el análisis en tres etapas:\n\nDescriptivo. Resumir visual y numéricamente los datos espaciales.\nIndicación. Explorar evidencia de estructuras espaciales o patrones.\nEstimación. Ajustar modelos estadísticos que permitan realizar inferencias o predicciones.",
    "crumbs": [
      "Presentación"
    ]
  },
  {
    "objectID": "Caps/01-Introduccion.html",
    "href": "Caps/01-Introduccion.html",
    "title": "1  Introducción",
    "section": "",
    "text": "1.1 Motivación\nGran parte del desarrollo clásico de la estadística se basa en la suposición de que las observaciones corresponden a realizaciones independientes e idénticamente distribuidas. Esta hipótesis es sensata en muestreos aleatorios o en experimentos controlados, y en particular implica que las observaciones no se influencían entre sí. La hipótesis es poco realista en muchos contextos donde las observaciones están influenciadas por su tiempo de ocurrencia, su ubicación en el espacio o alguna relación estructural propia del fenómeno.\nPara la incorporación de estructura espacial, podemos pensar en varias situaciones:\nLas herramientas con las que se cuenta hasta el momento son para preguntas del tipo quiero saber cómo se explica(n) la(s) propiedad(es) \\(Y\\) a partir de la(s) variable(s) \\(X\\), lo cual se planteó como un problema de regresión. Sin descartar esta herramienta, el considerar datos distribuidos en el espacio agrega una capa de complejidad al tener una estructura intrínseca a los fenómenos. Dicha estructura surge precisamente de considerar la ubicación del fenómeno y las condiciones de dicha ubicación. Los modelos espaciales surgen al reconocer que los datos están asociados a ubicaciones y que observaciones cercanas tienden a estar correlacionadas.\nPodemos considerar que entre las motivaciones principales para considerar modelos espaciales que muchos fenómenos reales como el clima, ecosistemas, epidemias, por mencionar algunos, no se comportan de manera independiente y la ubicación tiene un papel fundamental en su variabilidad. Basta pensar en que es más probable que sea parecida la temperatura entre dos puntos cercanos que entre dos puntos lejanos o que la prevalencia de una enfermedad dependa de factores ambientales o socioeconómicos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "Caps/01-Introduccion.html#motivación",
    "href": "Caps/01-Introduccion.html#motivación",
    "title": "1  Introducción",
    "section": "",
    "text": "Los lugares donde se puede encontrar agua en un país.\nLa popularidad de cierto artista en distintos lugares del mundo.\nPlayas susceptibles a tener problemas por huracanes.\nLa distribución de distintos recursos naturales (como recursos mineros).\nLa calidad de vida de la población en determinado territorio.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "Caps/01-Introduccion.html#antecedentes-históricos",
    "href": "Caps/01-Introduccion.html#antecedentes-históricos",
    "title": "1  Introducción",
    "section": "1.2 Antecedentes históricos",
    "text": "1.2 Antecedentes históricos\nEl interés por los datos espaciales se remonta a siglos atrás, cuando se comenzaron a representar fenómenos geográficos mediante mapas. Un ejemplo temprano es el trabajo de Halley (1686), quien superpuso en un mapa terrestre las direcciones de los vientos alisios y monzones, con el objetivo de comprender sus causas físicas.\nAunque estas representaciones eran esencialmente descriptivas, los modelos estadísticos espaciales surgieron mucho después. Student (1907) fue uno de los primeros en cuantificar datos espaciales al analizar conteos de partículas por unidad de área, encontrando que el número de células de levadura por cuadrado seguía una distribución de Poisson.\nFisher reconoció explícitamente la existencia de correlación espacial en experimentos agrícolas y de muestreo. En la Estación Experimental de Rothamsted, en las décadas de 1920 y 1930, promovió técnicas como aleatorización, bloqueo y replicación para controlar los efectos de la dependencia espacial. No obstante, estas estrategias sólo son eficaces para escalas espaciales comparables a las dimensiones experimentales; la correlación a otras escalas persiste.\nFairfield Smith (1938) también abordó la dependencia espacial al estudiar cómo el tamaño de las parcelas influye en la varianza del error, reconociendo implícitamente la necesidad de modelar la estructura espacial. Sin embargo, nso fue hasta trabajos como el de Whittle (1954) que comenzaron a desarrollarse modelos formales para describir procesos espaciales.\nHoy en día, el análisis de datos espaciales es fundamental en disciplinas como la geología, la ecología, las ciencias ambientales y la medicina. En muchos de estos contextos, no es viable aplicar métodos experimentales clásicos, lo que impulsa la necesidad de modelos estadísticos que reconozcan explícitamente la dependencia espacial.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "Caps/02-Exploratorio.html",
    "href": "Caps/02-Exploratorio.html",
    "title": "2  Análisis Exploratorio",
    "section": "",
    "text": "2.1 Tipos de datos espaciales\nEn esta primera sección se revisan herramientas básicas para un análisis descriptivo de datos espaciales.\nComo en otros modelos estadísticos, un punto de partida es revisar sobre qué tipo de objeto probabilista se busca hacer inferencia. Es muy útil recordar primero la noción de proceso estocástico tal como se da en (Klenke 2020).\nMuchas de las técnicas para estudiar estos procesos que varían en el tiempo dependen de que \\(I\\) es un conjunto ordenado. Además, para cada \\(\\omega\\in\\Omega\\), el mapeo \\(t\\mapsto Z_t(\\omega)\\) indica lo que hace el proceso a tiempo \\(t\\). A partir de esto, es inmediato extender la definición a un proceso espacial (o espacio-temporal).\nEn este texto se manejarán únicamente procesos espaciales, es decir, consideraremos que \\(t\\) es fijo. A una realización del proceso le denotaremos por \\(z={(z(x))}_{x\\in A}\\). En el contexto del análisis estadístico, se consideran distintos tipos de datos (o realizaciones ed \\(Z\\)).\nA partir de la estructura de esta realización \\(z\\), se pueden considerar distintos tipos de datos espaciales. De manera no exhaustiva, a continuación se presentan algunos de estos tipos de datos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análisis Exploratorio</span>"
    ]
  },
  {
    "objectID": "Caps/02-Exploratorio.html#tipos-de-datos-espaciales",
    "href": "Caps/02-Exploratorio.html#tipos-de-datos-espaciales",
    "title": "2  Análisis Exploratorio",
    "section": "",
    "text": "2.1.1 Datos de área o en retícula\nSi \\(A\\) es una unión numerable de unidades de área, decimos que la muestra \\(z\\) son datos de área o de retícula. Este tipo de estructuras es común en imágenes satelitales, en el análisis de suelos y algunos estudios experimentales en agricultura. También se encuentran las imágenes médicas y la teledetección. Los datos pueden representar toda la población (imagen completa) o una submuestra.\nEl énfasis en hablar de “unidades de área” tiene más sentido al considerar que un mapa con división territorial cumple con estas propiedades. Siguiendo a (Moraga 2023), a continuación se presentan un mapa del número de muertes repentinas de niños en cada condado de Carolina del Norte, EE.UU., en el año de 1974, reportado originalmente en (Pebesma 2022a).\n\n\nCódigo\nlibrary(sf)\nlibrary(mapview)\nd &lt;- st_read(system.file(\"shape/nc.shp\", package = \"sf\"), quiet = TRUE)\nmapview(d, zcol = \"SID74\")\n\n\n\n\n\n\nEn el anterior ejemplo, cada región del espacio es un condado. A continuación se presenta un mapa sobre la elevación de Luxemburgo, en el cual todas las regiones del mismo tamaño y están distribuidas de manera uniforme en el espacio, también tomado de (Moraga 2023).\n\n\nCódigo\nlibrary(terra)\nd &lt;- rast(system.file(\"ex/elev.tif\", package = \"terra\"))\nplot(d)\n\n\n\n\n\n\n\n\n\n\n\n2.1.2 Datos geoestadísticos\nEstos datos se miden de manera continua en el espacio, por lo que se consideran formas posiblemente irregulares. Una complicación de este tipo de datos es que normalmente sólo se dispone de observaciones en algunos puntos del espacio. Estos datos aparecen típicamente en cuestiones mineras, de ciencias del suelo, hidrológicas, meteorológicas u otros temas geológicos.\nComo ejemplo, se muestra la distribución de plomo superficial en mg por kg de tierra, en un terreno muestreado tras una inundación del río Meuse en Países Bajos. Estos datos son de la librería sp de R.\n\n\nCódigo\nlibrary(sp)\nlibrary(sf)\nlibrary(mapview)\n\ndata(meuse)\nmeuse &lt;- st_as_sf(meuse, coords = c(\"x\", \"y\"), crs = 28992)\nmapview(meuse, zcol = \"lead\",  map.types = \"CartoDB.Voyager\")\n\n\n\n\n\n\nEste tipo de datos se obtienen con mediciones de infiltrómetros revisando la capacidad del suelo para absorber agua.\nEn este tipo de datos, las ubicaciones de muestreo son generalmente irregulares y se tiene como objetivo predecir la variable en ubicaciones no observadas. Esto se hace bajo la hipótesis de continuidad espacial del campo y que la correlación entre observaciones depende de la distancia.\n\n\n2.1.3 Patrones puntuales\nEn este tipo de datos se centra el estudio en capítulos posteriores y en el caso de estudio. Aquí el dominio \\(A\\) se toma como aleatorio y las variables en \\(Z\\) sólo valen 1 o 0, indicando la ocurrencia o no de un evento. Estos patrones surgen de ubicar eventos, tales como aparición de enfermedades, nacimiento de especies, ubicación de viviendas, entre otros.\nComo ejemplo, se presentan los datos de pinos de hoja larga en Georgia, los cuales se pueden encontrar en la biblioteca spatstat de R. Lo que se mide es la presencia de pinos con longitud de hoja mayor a cierto parámetro. El objetivo del estudio era ver si los árboles con estas características están distribuidos uniformemente al azar en la región o si se tiene algún tipo de agrupamiento o regularidad.\n\n\nCódigo\nlibrary(spatstat)\n\ndata(longleaf)\n\nplot(longleaf, use.marks = FALSE, pch = 20, cex = 0.5, main = \"Pinos de hoja larga en Georgia\")\n\n\n\n\n\n\n\n\n\nSe pueden considerar versiones más generales de este tipo de datos, como los datos puntuales marcados. En los datos puntuales marcados se considera que las observaciones pueden ser de distintos tipos dada alguna característica cualitativa.\nLa característica principal de este tipo de datos es que el interés está centrado en la posición de los eventos, ya que no hay variables medidas continuamente en el espacio.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análisis Exploratorio</span>"
    ]
  },
  {
    "objectID": "Caps/02-Exploratorio.html#herramientas-descriptivas",
    "href": "Caps/02-Exploratorio.html#herramientas-descriptivas",
    "title": "2  Análisis Exploratorio",
    "section": "2.2 Herramientas descriptivas",
    "text": "2.2 Herramientas descriptivas\n\n2.2.1 El variograma\nUna herramienta de gran utilidad en el análisis de este tipo de procesos con estructura adicional es el variograma. La idea de este estadístico es estudiar empíricamente la estructura de covarianza del proceso espacial.\nLa idea se toma del contexto de series de tiempo, donde se busca medir la influencia de tiempos anteriores en el instante de estudio. Algunas de las definiciones de interés en el contexto de las series de tiempo se presentan a continuación, como se enuncian en (Rincón y De Jesús 2025).\n\nDefinición 2.4 (Estructura de covarianza y estacionareidad) Sea \\(X={(X_t)}_{t\\in\\mathbb{Z}}\\) una serie de tiempo.\n\nSi \\(X\\) tiene media finita, la función media es \\(t\\mapsto\\mu(t)=\\mathbb{E}[X_t]\\) para cada \\(t\\in\\mathbb{Z}\\).\nSi \\(X\\) tiene segundo momento finito, la función varianza es \\(t\\mapsto\\text{Var}(X_t)\\) para cada \\(t\\in\\mathbb{Z}\\).\nSi \\(X\\) tiene segundo momento, la función de autocovarianza es \\((s,t)\\mapsto\\gamma(s,t)=\\text{Cov}[X_s,X_t]\\).\n\\(X\\) es estrictamente estacionaria si para cualesquiera \\(k\\geq 1\\) y \\(\\tau\\in\\mathbb{Z}\\) se cumple que \\((X_1,\\ldots,X_k)\\overset{d}{=}(X_{1+\\tau},\\ldots,X_{k+\\tau})\\).\n\\(X\\) es débilmente estacionaria si satisface que \\(\\mu(t)=\\mu\\) y \\(\\gamma(t,t+\\tau)=\\gamma(\\tau)\\).\nSi \\(X\\) es estacionaria, la función de autocorrelación es \\(\\displaystyle\\rho(\\tau)=\\frac{\\gamma(\\tau)}{\\gamma(0)}\\).\n\n\nLa propiedad de ser estacionaria quiere decir que la estructura de correlación depende únicamente del tamaño del periodo que se revise y no de los instantes específicos en los que se vea el proceso, tal tamaño del periodo es la separación entre el inicio y el final del periodo. En el contexto de los datos espaciales, las nociones de estacionaridad se definen en términos de la distancia entre dos puntos.\n\nDefinición 2.5 (Proceso espacial estacionario) Sea \\(Z={(Z(s))}_{s\\in A\\subseteq\\mathbb{R}^d}\\) un proceso espacial. Decimos que \\(Z\\) es un proceso intrínsecamente estacionario si satisface que para todos \\(s,h\\in\\mathbb{R}^d\\)\n\\[\\mathbb{E}[Z(s+h)-Z(s)]=0\\quad\\text{y}\\quad\\text{Var}(Z(s+h)-Z(t))=2\\gamma(h),\\]\ndonde \\(\\gamma\\) es el variograma de \\(Z\\). \\(\\gamma\\) satisface que, para todos \\(s_1,\\ldots,s_k\\in A\\) y \\(\\alpha_1,\\ldots,\\alpha_n\\in\\mathbb{C}\\) tales que \\(\\alpha_1+\\cdots+\\alpha_n=0\\)\n\\[\\sum_{i=1}^k\\sum_{k=1}^k\\alpha_i\\overline{\\alpha}_j2\\gamma(s_i-s_j)\\leq 0.\\]\n\nEn pocas palabras, el variograma es una medida de la tendencia a ser diferentes de los valores según su distancia. Algunos comentarios que se pueden hacer a partir del variograma son las siguientes.\n\nCuando \\(h\\) es pequeño, se espera que \\(\\gamma(h)\\) sea pequeño, es decir, que las observaciones sean similares.\nCuando \\(h\\) crece, usualmente \\(\\gamma(h)\\) suele aumentar.\nA partir de cierto \\(h_0\\), usualmente para \\(h\\geq h_0\\) se tiene que \\(\\gamma(h)\\approx\\text{cte.}\\). A este \\(h_0\\) se le llama rango.\nHay veces que \\(\\gamma(h)\\to\\gamma_0&gt;0\\) cuando \\(h\\to 0\\). A este valor \\(\\gamma_0\\) se le llama efecto nugget (por las pepitas de oro encontradas en ríos, o en inglés, los ‘’gold nuggets’’).\n\nA continuación se presenta un estimador clásico del variograma, el cual fue propuesto por Mathéron en 1962.\n\nDefinición 2.6 (Variograma muestral) El variograma muestral del proceso espacial \\(Z\\) es\n\\[2\\widehat{\\gamma}(h)=\\frac{1}{|N(h)|}\\sum_{N(h)}{(Z(s_i)-Z(s_j))}^2,\\]\ndonde \\(N(h)=\\{(i,j)\\ :\\ s_i-s_j=h\\}\\) y \\(|N(h)|\\) es el número de elementos distintos en \\(N(h)\\).\n\nUna de las principales desventajas de este estimador es su sensibilidad a valores grandes de \\(Z\\). En (Cressie 2015) se puede revisar una variedad de ejemplos del uso de variograma. Aquí se da seguimiento al ejemplo del río Meuse de la sección Sección 2.1.2, presentando el variograma de los datos del plomo.\n\n\nCódigo\nlibrary(sp)\nlibrary(sf)\nlibrary(gstat)\n\ndata(meuse)\nmeuse_sp &lt;- meuse\ncoordinates(meuse_sp) &lt;- ~x + y\n\nvg_lead &lt;- variogram(log(lead) ~ 1, data = meuse_sp, cloud = FALSE)\n\nplot(vg_lead$dist, vg_lead$gamma, \n     xlab = \"Distancia (m)\", \n     ylab = \"Semivarianza\",\n     pch = 19, col = \"red\",\n     main = \"Variograma muestral de Plomo (log-escala)\",\n     cex.main = 1.2, cex.lab = 1.1)\n\ntext(vg_lead$dist, vg_lead$gamma, \n     labels = vg_lead$np, \n     pos = 3, cex = 0.8, col = \"blue\")\n\n\n\n\n\n\n\n\n\nLos números sobre cada punto en el mapa representan el número de pares de observaciones de \\(|N(h)|\\) usados para la semivarianza. La utilidad de estos números radica en que\n\nDan un criterio para medir la confiabilidad de cada punto: si un punto se basa en pocos pares, la estimación es menos confiable.\nAyudan a evaluar la dispersión de las distancias: muchos pares en una banda significa que esa distancia es común en el diseño del experimento.\n\n\n\n\n\nCressie, Noel. 2015. Statistics for Spatial Data. Revised. Wiley.\n\n\nKlenke, Achim. 2020. Probability Theory: A Comprehensive Course. Third. Wiley.\n\n\nMoraga, Paula. 2023. Spatial Statistics for Data Science: Theory and Practice with R. First. Chapman & Hall/CRC.\n\n\nPebesma, Edzer. 2022a. Simple Features for R. R-project.\n\n\nRincón, Luis, y Verónica De Jesús. 2025. Una introducción a las series de tiempo. First. La prensa de Ciencias.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Análisis Exploratorio</span>"
    ]
  },
  {
    "objectID": "Caps/03-Poisson.html",
    "href": "Caps/03-Poisson.html",
    "title": "3  Procesos de Poisson",
    "section": "",
    "text": "3.1 Proceso Poisson homogéneo\nEn este capítulo se presenta uno de los modelos básicos para el tratamiento de datos puntuales: el proceso Poisson. Para motivar su uso en problemas espaciales, primero recordaremos la génesis de éste en el contexto de los procesos en el tiempo.\nUno de los objetivos principales en el análisis de datos puntuales, es caracterizar conteos de eventos que ocurren de manera (presuntamente) aleatoria. Primero recordemos qué es un proceso de conteo.\nHay diversas variables aleatorias de conteo, pero la ley de eventos raros de Poisson (ver por ejemplo, (Klenke 2020)), sugiere que para el conteo de eventos con probabilidad ‘’baja’’ de ocurrir, es razonable utilizar variables aleatorias Poisson.\nExisten definiciones del proceso Poisson homogéneo equivalentes a Definición 3.2, pero ésta es de particular utilidad porque nos proporciona una manera de calcular explícitamente las distribuciones finito dimensionales de un proceso Poisson homogéneo y además éstas únicamente dependen de la longitud de los incrementos.\nCon estas propiedades, tenemos el siguiente estimador de máxima verosimilitud para el parámetro de intensidad \\(\\lambda\\).\nEl valor del estimador es intuitivo ya que dice que la intensidad estimada es el número de eventos por unidad de tiempo, lo cual es consistente con la intuición tras la palabra tasa. Además, se puede verificar que este es un estimador consistente e insesgado que además alcanza la cota de Cramér-Rao.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procesos de Poisson</span>"
    ]
  },
  {
    "objectID": "Caps/03-Poisson.html#proceso-poisson-homogéneo",
    "href": "Caps/03-Poisson.html#proceso-poisson-homogéneo",
    "title": "3  Procesos de Poisson",
    "section": "",
    "text": "Definición 3.1 (Proceso de conteo) Sea \\(N={(N_t)}_{t\\geq 0}\\) un proceso estocástico. \\(N\\) es un proceso de conteo si toma valores en \\(\\mathbb{N}\\cup\\{0\\}\\) y si \\(s&lt;t\\), entonces, \\(N_s\\leq N_t\\).\n\n\n\nDefinición 3.2 (Proceso Poisson homogéneo) Un proceso de conteo \\(N={(N_t)}_{t\\geq 0}\\) es un proceso Poisson homogéneo de intensidad \\(\\lambda&gt;0\\) si cumple que\n\n\\(N_0=0\\), casi seguramente.\nTiene incrementos independientes y estacionarios, casi seguramente.\nPara \\(s&lt;t\\), un incremento es tal que \\((N_t-N_s)\\sim\\text{Poi}(\\lambda(t-s))\\).\n\n\n\n\n\nTeorema 3.1 (Distribución conjunta y estimador máximo verosímil) Sea \\(N={(N_t)}_{t\\geq 0}\\) un proceso Poisson homogéneo con intensidad \\(\\lambda&gt;0\\) observado en el intervalo \\((0,T_0]\\). Supongamos que se registran \\(n\\) eventos en los tiempos \\(0&lt;w_1&lt;w_2&lt;\\cdots&lt;w_n\\leq T_0\\). Entonces\n\nDado que \\(N_{T_0}=n\\), la densidad conjunta de los tiempos de ocurrencia es\n\n\\[f_{W_1,\\ldots,W_n|N_{T_0}}(w_1,\\ldots,w_n|n)=\\frac{n!}{T_0^n},\\qquad\\text{para}\\ 0\\leq w_1&lt;\\cdots&lt;w_n\\leq T_0.\\]\n\nLa función de verosimilitud para \\(\\lambda\\) es\n\n\\[L(\\lambda;\\underline{x})=\\lambda^ne^{-\\lambda T_0}.\\]\n\nBajo esta formulación, el estimador máximo verosímil de \\(\\lambda\\) es\n\n\\[\\widehat{\\lambda}=\\frac{N_{T_0}}{T_0}.\\]\n\n\nPrueba. \n\nEsta primera afirmación es un resultado clásico de los procesos de Poisson homogéneos y puede revisarse por ejemplo en (Kingman 2007) o en (Karlin y Taylor 1981).\nComo \\(N\\) es un proceso Poisson homogéneo, la probabilidad de observar exactamente \\(n\\) eventos en el intervalo \\((0,T_0]\\) es\n\n\\[\\mathbb{P}[N_{T_0}=n]=e^{-\\lambda T_0}\\frac{{(\\lambda T_0)}^n}{n!}\\Bbb{1}_{\\mathbb{N}\\cup\\{0\\}}(n).\\]\nEntonces, por el punto anterior, la función de verosimilitud de \\(\\lambda\\) es\n\\[L(\\lambda;\\underline{x})\\propto\\mathbb{P}[N_{T_0}=n]f_{W_1,\\ldots,W_n|N_{T_0}}(w_1,\\ldots,w_n|n)=e^{-\\lambda T_0}\\frac{{(\\lambda T_0)}^n}{n!}\\frac{n!}{T_0^n}=\\lambda^n e^{-\\lambda T_0}.\\]\n\nTomamos la log-verosimilitud a partir del inciso anterior, de modo que\n\n\\[\\ell(\\lambda;\\underline{x})=\\ln L(\\lambda)=n\\ln\\lambda-\\lambda T_0.\\]\nEl punto crítico de esta función lo encontramos como\n\\[\\left.\\frac{d\\ell}{d\\lambda}\\right|_{\\lambda=\\lambda^*}=0\\iff\\frac{n}{\\lambda^*}-T_0=0\\implies\\lambda^*=\\frac{n}{T_0}.\\]\nVerificamos que es un máximo con el criterio de la segunda derivada, ya que\n\\[\\left.\\frac{d^2\\ell}{d\\lambda^2}\\right|_{\\lambda=\\lambda^*}=-\\frac{n}{\\lambda^2}&lt;0.\\]\nDe lo anterior, se concluye que el estimador máximo verosímil es\n\\[\\widehat{\\lambda}=\\frac{N_{T_0}}{T_0}.\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procesos de Poisson</span>"
    ]
  },
  {
    "objectID": "Caps/03-Poisson.html#proceso-poisson-espacial-homogéneo",
    "href": "Caps/03-Poisson.html#proceso-poisson-espacial-homogéneo",
    "title": "3  Procesos de Poisson",
    "section": "3.2 Proceso Poisson espacial homogéneo",
    "text": "3.2 Proceso Poisson espacial homogéneo\nSiguiendo la idea de que un proceso de Poisson sobre el tiempo cuenta cuántos puntos caen en cada intervalo de \\(\\mathbb{R}_+\\) tras arrojarlos a una intensidad \\(\\lambda&gt;0\\), es posible extender la noción del proceso Poisson a espacios más generales.\n\nDefinición 3.3 (Proceso Poisson espacial homogéneo) Sea \\(S\\subseteq\\mathbb{R}^d\\) un conjunto Lebesgue-medible y \\(\\mathcal{A}\\) una familia de subconjuntos Lebesgue-medibles de \\(S\\) cerrada bajo uniones e intersecciones finitas. Decimos que un proceso espacial \\(N={(N(A))}_{A\\in\\mathcal{A}}\\) es un proceso Poisson homogéneo de intensidad \\(\\lambda&gt;0\\) en la región \\(S\\) si - Para todo \\(A\\in\\mathcal{A}\\) se tiene que \\(N(A)\\sim\\text{Poi}(\\lambda|A|)\\), donde \\(|A|\\) representa la medida de Lebesgue del conjunto \\(A\\). - Para todos \\(A_1,\\ldots,A_n\\in\\mathcal{A}\\) disjuntos, las variables aleatorias \\(N(A_1),\\ldots,N(A_n)\\) son independientes. - Dado que \\(N(A)=n\\), las ubicaciones \\(X_1,\\ldots,X_n\\) de los eventos son uniformes en \\(A\\), es decir\n\\[f_{X_1,\\ldots,X_n|N(A)}(x_1,\\ldots,x_n|n)=\\frac{1}{{|A|}^n}.\\]\n\nAsí, un proceso Poisson espacial homogéneo es un proceso donde la intensidad con la que se arrojan puntos a una región \\(A\\) del espacio, es proporcional al tamaño de éste. Esto hace sentido con la idea intuitiva de que ‘’es más probable que contemos más puntos si el área es más grande’’.\nEn analogía, metodológica e intuitivamente, al caso temporal, tenemos el siguiente estimador para la intensidad de un proceso Poisson espacial homogéneo.\n\nTeorema 3.2 (Estimador máximo verosímil) Sea \\(N={(N(A))}_{A\\in\\mathcal{A}}\\) un proceso Poisson espacial homogéneo con intensidad \\(\\lambda&gt;0\\) observado en la región \\(A_0\\), de tamaño \\(|A_0|\\). Supongamos que se registran \\(n\\) eventos en las posiciones \\(x_1,x_2,\\ldots,x_n\\in A_0\\). Entonces el estimador máximo verosímil de \\(\\lambda\\) es\n\\[\\widehat{\\lambda}=\\frac{N(A_0)}{|A_0|}.\\]\n\n\nPrueba. Siguiendo la idea del caso temporal, la función de verosimilitud de \\(\\lambda\\) se puede calcular con las distribuciones conocidas como\n\\[\n\\begin{align*}\nL(\\lambda;\\underline{x})&\\propto f_{X_1,\\ldots,X_n|N(A_0)}(x_1,\\ldots,x_n)\\mathbb{P}[N(A_0)=n]\\\\\n&=e^{-\\lambda|A_0|}\\frac{{(\\lambda|A_0|)}^n}{n!}\\frac{1}{{|A_0|}^n}=\\frac{\\lambda^n}{n!}e^{-\\lambda|A|}.\n\\end{align*}\n\\]\nLa log-verosimilitud es\n\\[\\ell(\\lambda;\\underline{x})=n\\ln\\lambda-\\lambda|A_0|\\]\nEl punto crítico de esta función lo encontramos como\n\\[\\left.\\frac{d\\ell}{d\\lambda}\\right|_{\\lambda=\\lambda^*}=0\\iff\\frac{n}{\\lambda^*}-|A_0|=0\\implies\\lambda^*=\\frac{n}{|A_0|}.\\]\nVerificamos que es un máximo con el criterio de la segunda derivada, ya que\n\\[\\left.\\frac{d^2\\ell}{d\\lambda^2}\\right|_{\\lambda=\\lambda^*}=-\\frac{n}{\\lambda^2}&lt;0.\\]\nDe lo anterior, se concluye que el estimador máximo verosímil es\n\\[\\widehat{\\lambda}=\\frac{N(A_0)}{|A_0|}.\\]\n\nEl valor del estimador es intuitivo ya que dice que la intensidad estimada es el número de eventos por unidad de volumen, lo cual es consistente con la intuición tras la palabra tasa. Además, se puede verificar que este es un estimador consistente e insesgado que además alcanza la cota de Cramér-Rao.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procesos de Poisson</span>"
    ]
  },
  {
    "objectID": "Caps/03-Poisson.html#proceso-poisson-no-homogéneo",
    "href": "Caps/03-Poisson.html#proceso-poisson-no-homogéneo",
    "title": "3  Procesos de Poisson",
    "section": "3.3 Proceso Poisson no homogéneo",
    "text": "3.3 Proceso Poisson no homogéneo\nRegresamos al contexto temporal para motivar el siguiente modelo. Una de las principales debilidades del proceso Poisson homogéneo viene de la homogeneidad. El asumir que la intensidad es constante puede llevar a ideas como que los accidentes de tránsito ocurren a la misma tasa en la madrugada que en la tarde, y eso no es una hipótesis razonable, en general. La manera más inmediata de resolver esto es considerando que la intensidad ahora también varía en el tiempo.\n\nDefinición 3.4 (Proceso Poisson no homogéneo) Sea \\(\\lambda:[0,\\infty)\\to[0,\\infty)\\) una función tal que\n\\[\\int_0^\\infty\\lambda(t)dt=\\infty.\\]\nUn proceso de contar \\(N={(N_t)}_{t\\geq 0}\\) es un proceso Poisson no homogéneo con función de intensidad \\(\\lambda(t)\\) si satisface que\n\n\\(N_0=0\\) casi seguramente.\nTiene incrementos independientes.\n\\(\\mathbb{P}[N_{t+h}-N_t=1]=\\lambda(t)h+o(h)\\).\n\\(\\mathbb{P}[N_{t+h}-N_t\\geq 2]=o(h)\\).\n\n\nComo consecuencia de esta formulación infinitesimal, se tiene el siguiente resultado, el cual da la función de densidad de los incrementos de un proceso Poisson no homogéneo.\n\nTeorema 3.3 (Densidad de los incrementos) Sea \\(N={(N_t)}_{t\\geq 0}\\) un proceso Poisson no homogéneo con función de intensidad \\(\\lambda\\). Entonces, para cada \\(n\\geq 0\\) y \\(0\\leq s&lt;t\\), se tiene que\n\\[\\mathbb{P}[N_{t+s}-N_t=n]=\\exp\\left[-(\\Lambda(t+s)-\\Lambda(t))\\right]\\frac{{(\\Lambda(t+s)-\\Lambda(t))}^n}{n!},\\]\ndonde\n\\[\\Lambda(t)=\\int_0^t\\lambda(u)du\\]\nes la intensidad acumulada. Más aún, dado que han ocurrido \\(n\\) eventos en el intervalo \\((0,T]\\), los tiempos de ocurrencia de éstos son tales que\n\\[f_{W_1,\\ldots,W_n|N_t}(w_1,\\ldots,t_n|n)\\propto\\frac{1}{\\Lambda(t)}\\prod_{i=1}^n\\lambda(w_i).\\]\n\nEs importante notar que ahora se busca estimar una función. La función de verosimilitud de este problema es\n\\[L(\\lambda(t))=\\left[\\prod_{i=1}^n\\lambda(t_i)\\right]\\exp\\left(-\\Lambda(T)\\right).\\]\nLos métodos utilizados para estos problemas, son métodos para estimación de funciones. Hay distintas maneras de abordar este problema. El problema es que, como la función \\(\\lambda\\) no es propiamente una densidad, es necesario trabajar con alguna función relacionada que sí lo sea. Si consideramos la función \\(f:[0,T]\\to\\mathbb{R}\\) dada por\n\\[f(t)=\\frac{\\lambda(t)}{\\Lambda(T)},\\]\nahora sí tenemos una función de densidad en el intervalo \\([0,T]\\). Hay muchas maneras de resolver este problema de estimación de funciones. La manera más directa y como secuencia natural al Curso de Modelos Estadísticos, más específicamente al tema de regresión Poisson. Entonces, utilizando una función de enlace \\(\\log\\), se tiene el modelo Log-Lineal\n\\[\\log\\lambda(t)=\\beta_0+\\beta_1Z_1(t)+\\cdots+\\beta_pZ_p(t),\\]\ndonde \\(Z_1,\\ldots,Z_p\\) son covariables temporales y \\(\\beta_0,\\ldots,\\beta_p\\) son los coeficientes a estimar (podría verse como un problema de estimación de tendencia y estacionalidad de una serie de tiempo, por ejemplo). Otra manera sería considerar la versión empírica de \\(\\lambda\\) que se tiene por los tiempos \\(t_1,\\ldots,t_n\\) y utilizar algún método de suavizamiento por kernel de modo que se tendría\n\\[\\widehat{\\lambda}(t)=\\sum_{i=1}^n\\frac{1}{h}K\\left(\\frac{t-t_i}{h}\\right),\\]\npara \\(K\\) un kernel Gaussiano y un ancho de banda \\(h\\).\nUna manera de validar modelos de procesos Poisson no homogéneos y también de simularlos es el siguiente, que relaciona un proceso Poisson homogéneo con uno no homogéneo a partir de un cambio de tiempo determinista.\n\nTeorema 3.4 (Relación entre procesos Poisson homogéneos y no homogéneos)  \n\nSea \\({(N_t)}_{t\\geq 0}\\) un proceso Poisson no homogéneo con funciones de intensidad \\(\\lambda\\) y de intensidad acumulada \\(\\Lambda\\), con inversa generalizada \\(\\Lambda^{-1}\\). Entonces el proceso \\({(N_{\\Lambda^{-1}(t)})}_{t\\geq 0}\\) es un proceso Poisson homogéneo de intensidad \\(\\lambda=1\\).\nSea \\({(N_t)}_{t\\geq 0}\\) un proceso Poisson homogéneo de intensidad \\(\\lambda=1\\) y sea \\(\\lambda:[0,\\infty)\\to[0,\\infty)\\) una función no negativa tal que\n\n\\[\\int_0^\\infty\\lambda(t)dt=\\infty.\\]\nDefinimos la función \\(\\Lambda\\) como\n\\[\\Lambda(t)=\\int_0^t\\lambda(u)du.\\]\nEntonces el proceso \\({(N_{\\Lambda(t)})}_{t\\geq 0}\\) es un proceso Poisson no homogéneo con función de intensidad \\(\\lambda\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procesos de Poisson</span>"
    ]
  },
  {
    "objectID": "Caps/03-Poisson.html#proceso-poisson-espacial-no-homogéneo",
    "href": "Caps/03-Poisson.html#proceso-poisson-espacial-no-homogéneo",
    "title": "3  Procesos de Poisson",
    "section": "3.4 Proceso Poisson espacial no homogéneo",
    "text": "3.4 Proceso Poisson espacial no homogéneo\nCon las ideas de la sección anterior, un proceso Poisson espacial no homogéneo, intuitivamente, es uno en que la intensidad depende del punto del espacio en el que uno se encuentre. Teóricamente, la extensión no es tan directa como se pensaría en primera instancia.\n\nDefinición 3.5 (Proceso Poisson espacial no homogéneo) Sea \\(S\\subseteq\\mathbb{R}^d\\) un conjunto Lebesgue-medible y \\(\\mathcal{A}\\) una familia de subconjuntos Lebesgue-medibles de \\(S\\) cerrada bajo uniones e intersecciones finitas. Decimos que un proceso espacial \\(N={(N(A))}_{A\\in\\mathcal{A}}\\) es un proceso Poisson no homogéneo con función de intensidad \\(\\lambda:S\\to[0,\\infty)\\) en la región \\(S\\) si - Para todo \\(A\\in\\mathcal{A}\\) se tiene que \\(N(A)\\sim\\text{Poi}(\\lambda(A))\\), donde\n\\[\\Lambda(A)=\\int_A\\lambda(x)dx.\\]\n\nPara todos \\(A_1,\\ldots,A_n\\in\\mathcal{A}\\) disjuntos, las variables aleatorias \\(N(A_1),\\ldots,N(A_n)\\) son independientes.\nDado que \\(N(A)=n\\), las ubicaciones \\(X_1,\\ldots,X_n\\) de los eventos son tales que\n\n\\[ f_{X_1,\\ldots,X_n|N(A)}(x_1,\\ldots,x_n|n)=\\frac{1}{\\Lambda(A)}\\prod_{i=1}^n\\lambda(x_i). \\]\n\nEn este caso, la función de intensidad en realidad se toma como densidad para una medida, a la cual se le llama también medida de Poisson. Detalles teóricos sobre estos procesos de Poisson con intensidades \\(\\lambda\\) generales se pueden revisar en (Kingman 2007).\n\nEjemplo 3.1 Sean \\(S\\subseteq\\mathbb{R}^2\\) y \\(\\lambda(x,y)=e^{-(x^2+y^2)}\\). Entonces, si \\(A=\\{(x,y)\\ :\\ x^2+y^2\\leq r^2\\}\\), la medida de \\(A\\) respecto a \\(\\lambda\\) es\n\\[\\Lambda(A)=\\int_A e^{-(x^2+y^2)}dxdy=\\pi(1-e^{-r^2}).\\]\n\nLa manera en la que se puede hacer inferencia sobre la función \\(\\lambda\\) es la misma que en el caso temporal. La función de verosimilitud sobre la región \\(A\\) de este modelo es\n\\[L(\\lambda(t))=\\left[\\prod_{i=1}^n\\lambda(x_i)\\right]\\exp(-\\Lambda(A)).\\]\nEl modelo Log-Lineal en este caso es\n\\[\\log\\lambda(s)=\\beta_0(s)+\\beta_1Z(s).\\]\nUna hipótesis usual es considerar que \\(Z={(Z(s))}_{s\\in A}\\) es un campo Gaussiano de media 0. Dos métodos clásicos para la estimación son los siguientes:\n\nCon una discretización del espacio en una rejilla de \\(n_1\\times n_2=N\\) celdas \\({(s_{ij})}_{(i,j)\\in\\{1,\\ldots,n_1\\}\\times\\{1,\\ldots,n_2\\}}\\). El número promedio de eventos por celda es\n\n\\[\\Lambda_{ij}=\\int_{s_{ij}}\\exp(\\eta(s))ds\\approx|s_{ij}|\\exp(\\eta_{ij}).\\]\nEntonces, dado un campo latente \\(\\eta_{ij}\\), el número de observaciones en la rejilla es tal que\n\\[(y_{ij}|\\eta_{ij})\\sim\\text{Poi}(|s_{ij}|\\exp(\\eta_{ij})),\\]\nEl campo latente puede estimarse a partir de otras covariables y efectos aleatorios como\n\\[\\eta_{ij}=c(s_{ij})\\beta+f_s(s_{ij})+f_u(s_{ij}),\\]\ndonde \\(\\beta=(\\beta_0,\\beta_1,\\ldots,\\beta_p),\\ c(s_{ij})=(1,c_1(s_{ij}),\\ldots,c_p(s_{ij})),\\ f_s\\) es un ruido dependiente de la estructura espacial y \\(f_u\\) es un ruido no necesariamente dependiente del espacio.\n\nCon un proceso análogo al autorregresivo de las series de tiempo\n\n\\[Z(s)=\\sum_{i=1}^nZ_i\\phi_i(s),\\]\ndonde \\((Z_1,\\ldots,Z_n)\\) es un vector Gaussiano y \\({(\\phi_i(s))}_{i=1}^n\\) es una base de funciones deterministas. Una alternativa usual es considerar que el campo Gaussiano tiene matriz de covarianza como en el variograma de Mathéron presentado en la sección Sección 2.2.1.\nEste modelo no se limita únicamente a que tome valores de puntos en el espacio. La definición contempla casos en los que la función de intensidad sea de la forma \\(\\lambda:[0,\\infty)\\times\\mathbb{R}^d\\to\\mathbb{R}_+\\) como \\(\\lambda=\\lambda(t,x)\\), es decir, que la intensidad dependa del instante y de la ubicación. Un problema para ilustrar esta forma de \\(\\lambda\\) es el de las lluvias, que su intensidad puede depender de la hora del día y del lugar del mundo del que se trate.\nDe la misma manera que con el análisis de procesos temporales, es posible usar suavizamiento por kernel para estimar \\(\\lambda\\) a partir de una medida empírica. Como se mencionó en el caso temporal, la función \\(\\lambda\\) no necesariamente es una densidad, pero la función\n\\[f(x)=\\frac{1}{\\Lambda(A)}\\lambda(x)\\]\nsí es una densidad en la región \\(A\\). Entonces, los estimadores de kernel para \\(f\\) y \\(\\lambda\\) basados en un conjunto de observaciones \\(X_1,\\ldots,X_n\\) están dados por\n\\[\n\\begin{align*}\n\\widehat{f}(x)&=\\frac{1}{n}\\sum_{i=1}^n\\frac{1}{h^2}K\\left(\\frac{x-x_i}{h}\\right),\\\\\n\\widehat{\\lambda}(x)&=\\sum_{i=1}^n\\frac{1}{h^2}K\\left(\\frac{x-x_i}{h}\\right),\n\\end{align*}\n\\]\ndonde \\(h\\) es un ancho de banda. Una elección usual para \\(K\\) es la normal multivariada.\n\n\n\nManera en la que se pueden agrupar los eventos para suavizar por Kernel",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procesos de Poisson</span>"
    ]
  },
  {
    "objectID": "Caps/03-Poisson.html#pruebas-de-clústering",
    "href": "Caps/03-Poisson.html#pruebas-de-clústering",
    "title": "3  Procesos de Poisson",
    "section": "3.5 Pruebas de clústering",
    "text": "3.5 Pruebas de clústering\nLa última propiedad enunciada en la definición Definición 3.3 hace que al proceso Poisson espacial homogéneo también se le llame el modelo de aleatoriedad espacial completa o CSR por sus siglas en inglés (complete spatial randomness). Si bien la mayoría de procesos están lejos de ser CSR, éste ayuda a diferenciar entre patrones regulares y conglomerados (o clusterizados).\nDada una muestra de puntos, un buen primer paso es preguntarse si hay evidencia para rechazar la hipótesis de que se trate de un CSR.\n\n3.5.1 Prueba con quadrat\nUn método para dar evidencia a favor o en contra de la hipótesis nula \\(H_0\\) ser CSR es con una prueba \\(\\chi^2\\) (ver (Moraga 2023)). El método quadrat coincide en particionar la región de estudio en \\(r\\) renglones y \\(c\\) columnas, de modo que se obtenga una retícula de regiones disjuntas de la misma área (quadrats). Así, bajo \\(H_0\\), el número esperado de observaciones en cualquier región de la retícula es el mismo: sean \\(n\\) el número de observaciones, \\(m\\) el número de quadrats y \\(n_i\\) el número de puntos en el \\(i\\)-ésimo quadrat; entonces el número esperado de puntos en cada quadrat es \\(n^*=n/m\\).\nDado lo anterior, el estadístico de prueba se puede calcular por\n\\[X^2=\\sum_{i=1}^m\\frac{{(n_i-n^*)}^2}{n^*}.\\]\nSe puede verificar que, bajo \\(H_0\\), entonces \\(X^2\\sim\\chi^2_{m-1}\\).\nEs muy importante destacar que este método depende de la configuración de quadrats (puede haber regiones sin puntos). También esta prueba no puede distinguir entre distintos patrones localmente.\nEn R se tiene la función quadrat.test() para probar la hipótesis de CSR. La interpretación es de acuerdo a la siguiente clave:\n\nalternative = “two.sided” prueba \\(H_0:\\) CSR vs. \\(H_a:\\) no CSR (regular o clusterizada).\nalternative = “regular” prueba \\(H_0:\\) CSR o clusterizada vs. \\(H_a:\\) regular.\nalternative = “clustered” prueba \\(H_0:\\) CSR o regular vs. \\(H_a:\\) clusterizada.\n\n\n\n3.5.2 Las funciones K y L de Ripley\nPensando en datos puntuales sobre regiones del espacio \\(S\\subseteq\\mathbb{R}^2\\), se puede usar otro estadístico para probar la homogeneidad del proceso puntual.\n\nDefinición 3.6 (Funciones K y L de Ripley) Sea \\(N={(N(A))}_{A\\in\\mathcal{A}}\\) un proceso Poisson espacial en \\(\\mathbb{R}^2\\) con función de intensidad \\(\\lambda\\).\n\nLa función K de Ripley es la función dada por\n\n\\[K(s)=\\frac{1}{\\lambda}\\mathbb{E}_0[N(B_r(0)\\backslash\\{0\\})],\\]\ndonde \\(\\mathbb{E}_0\\) es la esperanza condicionada a que haya un punto en el origen y \\(B_r(0)\\) es la bola de radio \\(r\\) centrada en el origen.\n\nLa función L de Ripley es la función dada por\n\n\\[L(r)=\\sqrt{\\frac{K(r)}{\\pi}}.\\]\n\nNotemos que bajo la hipótesis de CSR, la función \\(\\lambda\\) es constante y las funciones de Ripley están dadas explícitamente por\n\\[\n\\begin{align*}\nK(r)&=\\frac{1}{\\lambda}\\mathbb{E}_0[N(B_r(0)\\backslash\\{0\\})]=\\frac{1}{\\lambda}\\mathbb{E}_0[N(B_r(0))]\\\\\n&=\\frac{|B_r(0)|\\lambda}{\\lambda}=\\pi r^2,\\\\\nL(r)&=\\sqrt{\\frac{K(r)}{\\pi}}=\\sqrt{\\frac{\\pi r^2}{\\pi}}=r.\n\\end{align*}\n\\]\nDada la forma de la función \\(K\\) bajo CSR, se tiene el siguiente criterio:\n\nSi \\(K(r)&gt;\\pi r^2\\) o, equivalentemente, \\(L(r)&gt;r\\), la función de intensidad favorece el clústering.\nSi \\(K(r)&lt;\\pi r^2\\) o, equivalentemente, \\(L(r)&lt;r\\), la función de intensidad favorece la dispersión.\n\nUna manera de estimar la función \\(K\\) es utilizando que es un conteo. Para hacer éste, es necesario tomar en cuenta que los eventos contados cerca de la frontera de una región \\(A\\) pueden ser bajos. Por ello s eintroduce un peso \\(w_{ij}\\) correspondiente al recíproco a la proporción del círculo con centro en \\(x_i\\) y radio \\(d_{ij}\\) contenido en \\(A\\).\n\nDefinición 3.7 (Estimadores de las funciones de Ripley) Sea \\(X=\\{X_1,\\ldots,X_n\\}\\) un patrón de puntos en \\(S\\). La función \\(K\\) de Ripley empírica está dada por\n\\[\\widehat{K}(r)=\\frac{1}{\\widehat{\\lambda}n}\\sum_{i=1}^n\\sum_{j\\neq i}w_{ij}^{-1}\\Bbb{1}_{d_{ij}\\leq r}.\\]\nBajo la hipótesis de CSR, el estimador de \\(\\lambda\\) es \\(\\displaystyle\\widehat{\\lambda}=\\frac{n-1}{|S|}\\), entonces la función \\(K\\) empírica es\n\\[\\widehat{K}(r)=\\frac{|S|}{n(n-1)}\\sum_{i=1}^n\\sum_{j\\neq i}w_{ij}^{-1}\\Bbb{1}_{d_{ij}\\leq r}.\\]\nDel mismo modo, la la función \\(L\\) de Ripley empírica está dada por\n\\[\\widehat{L}(r)=\\sqrt{\\frac{\\widehat{K}(r)}{\\pi}}.\\]\n\nLos intervalos de confianza para estas funciones empíricas típicamente son intervalos bootstrap. La idea de utilizar las funciones de Ripley es parecida a la de las gráficas QQ en inferencia de distribuciones: entre más cerca esté el proceso de ser homogéneo en el espacio, más parecidas serán las funciones teórica y empírica.\nEn el siguiente ejemplo se muestra un ejemplo del uso de estas funciones con datos simulados directamente de un proceso Poisson homogéneo.\n\nEjemplo 3.2 Primero generamos un proceso Poisson homogéneo de intensidad \\(\\lambda=100\\) y revisamos la región \\(A=[0,1]\\times[0,1]\\).\n\n\nCódigo\nlibrary(spatstat)\n\nset.seed(612000)\nX &lt;- rpoispp(lambda = 100, win = owin(c(0,1), c(0,1)))\n\nplot(X, \n     main = \"Proceso de Poisson Homogéneo\",\n     pch = 20,                      \n     cols = \"blue\",                  \n     show.window = TRUE,             \n     axes = TRUE,                    \n     xlab = \"X\",          \n     ylab = \"Y\"        \n     )\n\n\n\n\n\n\n\n\n\nA partir de la simulación, calculamos el estimador de \\(\\lambda\\) bajo el supuesto de CSR.\n\n\nCódigo\nlambda_hat&lt;- data.frame(\"lambda_hat=\",intensity(X)) \nlambda_hat\n\n\n  X.lambda_hat.. intensity.X.\n1    lambda_hat=           94\n\n\nEste estimador sí es bastante parecido al valor real utilizado. Así, la función \\(K\\) empírica superpuesta a la teórica se ve como\n\n\nCódigo\nK &lt;- Kest(X, correction = \"border\")\nplot(K)\n\n\n\n\n\n\n\n\n\nO, más claramente con la función \\(L\\), se ve como\n\n\nCódigo\nL&lt;-Lest(X, correction = \"border\")\nplot(L)\n\n\n\n\n\n\n\n\n\nAl ser las funciones empíricas parecidas a las funciones teóricas, podemos afirmar que los datos trabajados sí corresponden a un CSR.\nPara sustentar esta última afirmación, podemos utilizar la prueba quadrat, la cual también da evidencia a favor de la hipótesis de CSR.\n\n\nCódigo\nquadrat.test(X, nx = 4, ny = 4)\n\n\n\n    Chi-squared test of CSR using quadrat counts\n\ndata:  X\nX2 = 10.17, df = 15, p-value = 0.3822\nalternative hypothesis: two.sided\n\nQuadrats: 4 by 4 grid of tiles\n\n\n\n\n\n\n\nKarlin, Samuel, y Howard Taylor. 1981. A Second Course in Stochastic Processes. First. Academic Press.\n\n\nKingman, John. 2007. Poisson Processes. Second. Claredon Press.\n\n\nKlenke, Achim. 2020. Probability Theory: A Comprehensive Course. Third. Wiley.\n\n\nMoraga, Paula. 2023. Spatial Statistics for Data Science: Theory and Practice with R. First. Chapman & Hall/CRC.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Procesos de Poisson</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Cressie, Noel. 2015. Statistics for Spatial Data. Revised.\nWiley.\n\n\nKarlin, Samuel, and Howard Taylor. 1981. A Second Course in\nStochastic Processes. First. Academic Press.\n\n\nKingman, John. 2007. Poisson Processes. Second. Claredon Press.\n\n\nKlenke, Achim. 2020. Probability Theory: A Comprehensive\nCourse. Third. Wiley.\n\n\nMoraga, Paula. 2023. Spatial Statistics for Data Science: Theory and\nPractice with r. First. Chapman & Hall/CRC.\n\n\nPebesma, Edzer. 2022a. Simple Features for r. R-project.\n\n\nRincón, Luis, and Verónica De Jesús. 2025. Una Introducción a Las\nSeries de Tiempo. First. La prensa de Ciencias.",
    "crumbs": [
      "References"
    ]
  }
]